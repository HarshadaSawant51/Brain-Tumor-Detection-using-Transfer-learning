{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LoadModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRAIE1qKrp9F"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "from os import listdir\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from os import listdir\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import os\n",
        "import seaborn as sns\n",
        "from keras.applications.vgg16 import VGG16 \n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg2ExE3br02w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zg8hPOrr06R"
      },
      "source": [
        "def crop_brain_contour(image, plot=False):\n",
        "    \n",
        "    \n",
        "    # Convert the image to grayscale, and blur it slightly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Threshold the image, then perform a series of erosions +\n",
        "    # dilations to remove any small regions of noise\n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "    # Find contours in thresholded image, then grab the largest one\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    \n",
        "\n",
        "    # Find the extreme points\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "    \n",
        "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
        "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
        "\n",
        "    if plot:\n",
        "        plt.figure()\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image)\n",
        "        \n",
        "        plt.tick_params(axis='both', which='both', \n",
        "                        top=False, bottom=False, left=False, right=False,\n",
        "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "        \n",
        "        plt.title('Original Image')\n",
        "            \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(new_image)\n",
        "\n",
        "        plt.tick_params(axis='both', which='both', \n",
        "                        top=False, bottom=False, left=False, right=False,\n",
        "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "        plt.title('Preprocessed Image')\n",
        "        \n",
        "        plt.show()\n",
        "    \n",
        "    return new_image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QIE44QRr0-4",
        "outputId": "9f65242c-12df-410c-f933-019a7b2d0d2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk5MwtYttEjw",
        "outputId": "d9f8308f-2e9b-4ba0-91d7-cbbcee1e0eca"
      },
      "source": [
        "vggmodel = load_model(\"/content/drive/My Drive/VGG_model.h5\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UcobXlmtEo0"
      },
      "source": [
        "path=\"/content/drive/My Drive/augmented_data/no/aug_28 no_0_5806.jpg\"\n",
        "img=cv2.imread(path)\n",
        "img = crop_brain_contour(img, plot=False)\n",
        "img = cv2.resize(img, dsize=(256,256), interpolation=cv2.INTER_CUBIC)\n",
        "img = img / 255.\n",
        "from keras.preprocessing import image\n",
        "test_image = image.img_to_array(img)\n",
        "test_image = np.expand_dims(test_image, axis = 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yORjHKJbtEsw"
      },
      "source": [
        "test_f=vggmodel.predict(test_image)\n",
        "test_f=test_f.reshape(test_f.shape[0],-1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYU0HmL2r1Cw",
        "outputId": "4d0c869d-b737-4d49-d292-e9b33471af73"
      },
      "source": [
        "import pickle\n",
        "from sklearn import svm\n",
        "filename = '/content/drive/My Drive/finalized_model.sav' \n",
        "# load the model from disk\n",
        "svm_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "prediction_svm=svm_model.predict(test_f)\n",
        "if(prediction_svm[0]==0):\n",
        "   print(\"No tumor detected\")\n",
        "else:\n",
        "   print(\"Tumor detected\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No tumor detected\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}